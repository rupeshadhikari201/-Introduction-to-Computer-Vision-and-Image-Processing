{"cells":[{"cell_type":"markdown","id":"2ca18747-9db7-42a4-b968-d365a9606444","metadata":{},"outputs":[],"source":["<p>\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"adf979f9-01cc-423a-98e8-98f8b48b7b9a","metadata":{},"outputs":[],"source":["<h1>Histogram and Intensity Transformations</h1>\n"]},{"cell_type":"markdown","id":"976f1657-273f-4e7c-ba3d-fdc2664dbd1a","metadata":{},"outputs":[],"source":["Estimated time needed: **40** minutes\n"]},{"cell_type":"markdown","id":"1fb52a5a-e189-451c-bc5a-57273971f016","metadata":{},"outputs":[],"source":["<h2>Objectives</h2>\n"]},{"cell_type":"markdown","id":"70743f75-41b3-4d36-a1e3-b8c19cf69bf5","metadata":{},"outputs":[],"source":["Pixel Transforms are operations you perform one pixel at a time. In this lab, you will start by creating histograms. Histograms display the intensity of the image and can be used to optimize image characteristics. You will then apply Intensity Transformations, making objects easier to see by improving image contrast and brightness. In the last portion of the lab, you will use thresholding to segment objects from images.\n"]},{"cell_type":"markdown","id":"667b0a6b-4fb2-4252-88a2-26c2781a4771","metadata":{},"outputs":[],"source":["<ul>\n","    <li><a href='#PT'>Pixel Transforms  </a>\n","        <ul>\n","            <li>Histograms </li>\n","            <li>Intensity Transformations</li>\n","            <li>Thresholding and Simple Segmentation </li>   \n","</ul>\n"]},{"cell_type":"markdown","id":"65a66bdc-741a-4308-a3c9-1039e9c8f129","metadata":{},"outputs":[],"source":["----\n"]},{"cell_type":"markdown","id":"59e92749-3af3-47cd-bb08-4dd26805b5ce","metadata":{},"outputs":[],"source":["Download the image for the lab\n"]},{"cell_type":"code","id":"7d5e8955-0252-44ac-9de7-245acdd188b1","metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/goldhill.bmp -O goldhill.bmp\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/cameraman.jpeg -O cameraman.jpeg\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/zelda.png -O zelda.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/mammogram.png -O mammogram.png"]},{"cell_type":"markdown","id":"aae3a986-0af2-40b1-8d1d-0dcdf63e08c9","metadata":{},"outputs":[],"source":["We will be using these imported functions in the lab\n"]},{"cell_type":"code","id":"010ab5ea-8379-4b8b-a918-1c2462802a97","metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np"]},{"cell_type":"markdown","id":"56a64142-18c3-40fe-98a9-c30405f8e02d","metadata":{},"outputs":[],"source":["First, lets define a helper function to plot two images side-by-side. You will not need to understand this code at this moment, but this function will be used repeatedly in this tutorial to showcase the results. \n"]},{"cell_type":"code","id":"1ef60c59-bc6e-426d-a9f1-271c16bd6e45","metadata":{},"outputs":[],"source":["def plot_image(image_1, image_2,title_1=\"Orignal\", title_2=\"New Image\"):\n    plt.figure(figsize=(10,10))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image_1,cmap=\"gray\")\n    plt.title(title_1)\n    plt.subplot(1, 2, 2)\n    plt.imshow(image_2,cmap=\"gray\")\n    plt.title(title_2)\n    plt.show()"]},{"cell_type":"markdown","id":"6bfc24e7-8ce1-4a30-8b17-53a9f35a7849","metadata":{},"outputs":[],"source":["Lets define another helper function. The following one will plot two histograms side-by-side. Again, you do not need to understand the body of this function at this moment.\n"]},{"cell_type":"code","id":"cb1f9717-f753-4ee0-8132-d4035b4ac862","metadata":{},"outputs":[],"source":["def plot_hist(old_image, new_image,title_old=\"Orignal\", title_new=\"New Image\"):\n    intensity_values=np.array([x for x in range(256)])\n    plt.subplot(1, 2, 1)\n    plt.bar(intensity_values, cv2.calcHist([old_image],[0],None,[256],[0,256])[:,0],width = 5)\n    plt.title(title_old)\n    plt.xlabel('intensity')\n    plt.subplot(1, 2, 2)\n    plt.bar(intensity_values, cv2.calcHist([new_image],[0],None,[256],[0,256])[:,0],width = 5)\n    plt.title(title_new)\n    plt.xlabel('intensity')\n    plt.show()"]},{"cell_type":"markdown","id":"6aa92c93-d8f8-4749-9cec-e821b38ef3e9","metadata":{},"outputs":[],"source":["# Histograms  \n"]},{"cell_type":"markdown","id":"22c4f724-d37c-4742-a788-820084430146","metadata":{},"outputs":[],"source":["A histogram counts the number of occurrences of the intensity values of pixels, and it's a useful tool for understanding and manipulating images. We use <code>cv.calcHist()</code> to generate the histogram. Here are the parameter values:\n","<p>\n","    <code>cv2.calcHist(CV array:<b>[image]</b> this is the image channel:<b>[0]</b>,for this course it will always be <b>[None]</b>,the number of bins:<b>[L]</b>,the range of index of bins:<b>[0,L-1]</b>) </code>   \n","</p>\n","For real images, <code>L</code> is <code>256</code>.\n"]},{"cell_type":"markdown","id":"c7e5c1e2-4d29-49ed-8815-79e25c1d092f","metadata":{},"outputs":[],"source":["## Toy Example\n"]},{"cell_type":"markdown","id":"54497458-73a4-4812-8784-998d07eef796","metadata":{},"outputs":[],"source":["Consider the toy array with intensity values ranging from 0 to 2. We can create a histogram. Its first element is the number of zeros in the image (in this case, 1); its second element is the number of ones in the image (in this case, 5), and so on.\n"]},{"cell_type":"code","id":"570af5a0-8b19-4088-bcf9-af3d4f907966","metadata":{},"outputs":[],"source":["toy_image = np.array([[0,2,2],[1,1,1],[1,1,2]],dtype=np.uint8)\nplt.imshow(toy_image, cmap=\"gray\")\nplt.show()\nprint(\"toy_image:\",toy_image)"]},{"cell_type":"markdown","id":"639a36e7-048e-4be0-a8ea-077cde1df14d","metadata":{},"outputs":[],"source":["We can use the <code>caclHist</code> function, in this case, we use only three bins as there are only three values, and the index of the bins are from 1 to 3.\n","\n","**TODO:** @Joe \n"]},{"cell_type":"code","id":"b9f54a98-b5ff-40d0-b8dd-bff5f85bff45","metadata":{},"outputs":[],"source":["plt.bar([x for x in range(6)],[1,5,2,0,0,0])\nplt.show()"]},{"cell_type":"code","id":"9b74fb4b-2b69-4a7e-b5a1-6af429a1bc28","metadata":{},"outputs":[],"source":["plt.bar([x for x in range(6)],[0,1,0,5,0,2])\nplt.show()"]},{"cell_type":"markdown","id":"05562215-67b8-41fa-9247-cc322825ca44","metadata":{},"outputs":[],"source":["The histogram is a function where $h[r]$  where   $r \\in {0,1,2} $. In the above example  $h[0]=1$,$h[1]=5$ and $h[2]=3$\n"]},{"cell_type":"markdown","id":"e420d228-03a6-4d91-8a0f-d2c658e87f62","metadata":{},"outputs":[],"source":["## Gray Scale Histograms \n"]},{"cell_type":"markdown","id":"5bed5fc5-5482-4aa6-b0bc-c4c34f779034","metadata":{},"outputs":[],"source":["\n","\n","Histograms are used in grayscale images.  Grayscale images are used in many applications, including medical and industrial. Color images are split into luminance and chrominance. The luminance is the grayscale portion and is usually processed in many applications. Consider the following \"Gold Hill\" image:\n"]},{"cell_type":"code","id":"6a9c9b16-469a-4e62-8732-18f082295459","metadata":{},"outputs":[],"source":["goldhill = cv2.imread(\"goldhill.bmp\",cv2.IMREAD_GRAYSCALE)\nplt.figure(figsize=(10,10))\nplt.imshow(goldhill,cmap=\"gray\")\nplt.show()"]},{"cell_type":"markdown","id":"2714f841-651a-4306-b4a2-0892e1275c99","metadata":{},"outputs":[],"source":["We can calculate the histogram using the `calcHist` function from the `cv2` module as follows, the shape is 256.\n"]},{"cell_type":"code","id":"b9ecba2e-5d8b-4ea8-bec1-613541f506b0","metadata":{},"outputs":[],"source":["hist = cv2.calcHist([goldhill],[0], None, [256], [0,256])"]},{"cell_type":"markdown","id":"a63da640-3105-439b-84ae-fb803a2a5438","metadata":{},"outputs":[],"source":["We can plot it as a bar graph, the $x$-axis are the pixel intensities and the $y$-axis is the number of times of occurrences that the corresponding pixel intensity value on $x$-axis occurred.\n"]},{"cell_type":"code","id":"5fe389e8-1924-42ca-9ca9-4ffa4ec6e5f7","metadata":{},"outputs":[],"source":["intensity_values = np.array([x for x in range(hist.shape[0])])\nplt.bar(intensity_values, hist[:,0], width = 5)\nplt.title(\"Bar histogram\")\nplt.show()"]},{"cell_type":"markdown","id":"569119e8-dd77-47cd-874c-4ad6dd9d7f94","metadata":{},"outputs":[],"source":["The histogram is a function where $h[r]$  where   $r \\in {0,1,..,255} $.\n"]},{"cell_type":"markdown","id":"f99dccbe-7c84-4754-aa0a-5193c9324753","metadata":{},"outputs":[],"source":["We can convert it to a probability mass function by normalizing it by the number of pixels:\n"]},{"cell_type":"code","id":"7febd783-eb54-41ef-a829-000a99d79d60","metadata":{},"outputs":[],"source":["PMF = hist / (goldhill.shape[0] * goldhill.shape[1])"]},{"cell_type":"markdown","id":"13695a73-e84e-4649-8827-430a6af4d3e4","metadata":{},"outputs":[],"source":["We can plot as a continuous function:\n"]},{"cell_type":"code","id":"fe331789-9ae6-4c0c-b01a-bd1ac29bc14e","metadata":{},"outputs":[],"source":["plt.plot(intensity_values,hist)\nplt.title(\"histogram\")\nplt.show()"]},{"cell_type":"markdown","id":"df49f867-50d7-47b6-9630-02852a48ee3a","metadata":{},"outputs":[],"source":["\n","We can also apply a histogram to each image color channel:\n"]},{"cell_type":"code","id":"0d316f95-9891-44db-be5f-fd230c99774f","metadata":{},"outputs":[],"source":["baboon = cv2.imread(\"baboon.png\")\nplt.imshow(cv2.cvtColor(baboon,cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"9cd34e4f-ff20-499a-8b24-203c36c779db","metadata":{},"outputs":[],"source":["In the loop, the value for <code>i</code> specifies what color channel <code>calcHist</code> is going to calculate the histogram for.   \n"]},{"cell_type":"code","id":"6d2270ed-661a-45f1-a3eb-1a43f751bca3","metadata":{},"outputs":[],"source":["color = ('blue','green','red')\nfor i,col in enumerate(color):\n    histr = cv2.calcHist([baboon],[i],None,[256],[0,256])\n    plt.plot(intensity_values,histr,color = col,label=col+\" channel\")\n    \n    plt.xlim([0,256])\nplt.legend()\nplt.title(\"Histogram Channels\")\nplt.show()"]},{"cell_type":"markdown","id":"5bcdc277-c415-4415-89c5-7a2984121b9d","metadata":{},"outputs":[],"source":["#  Intensity Transformations\n"]},{"cell_type":"markdown","id":"93323653-3dd2-4ee5-9c4a-35171e458323","metadata":{},"outputs":[],"source":["It's helpful to think of an image as a function $f(x,y)$ instead of an array at this point, where `x` is the row index and `y` is the column index. You can apply a transformation $T$ to the image and get a new image: \n","$$\n","g(x,y)=T(f(x,y))\n","$$\n","\n","An Intensity Transformation depends on only one single point $(x,y)$. For example, you can apply a linear transform $g(x,y) = 2f(x,y) + 1$; this will multiply each image pixel by two and add one.\n","\n","As the Intensity transforms only depend on one value; as a result, it is sometimes referred to as a gray-level mapping. The variable if $r$ is the gray level intensity, similar to the histogram values. The new output s is given by:\n","\n","$$\n","s=T(r)\n","$$\n"]},{"cell_type":"markdown","id":"e490a066-f67a-461c-b41e-3d3067e4f6e6","metadata":{},"outputs":[],"source":["## Image Negatives\n"]},{"cell_type":"markdown","id":"2b8a0a97-ce53-480f-a864-8ba31a656a0b","metadata":{},"outputs":[],"source":["Consider an image with $L$ intensity values ranging from $[0,L-1]$.  We can reverse the intensity levels by applying the following:\n","$$\n","g(x,y)=L-1-f(x,y)\n","$$\n","\n","Using the intensity transformation function notation \n","$$\n","s = L - 1 - r\n","$$\n","\n","This is called the image negative. For $L= 256$ the formulas simplifys to:\n","$$\n","g(x,y)=255-f(x,y) \\qquad \\mbox{and} \\qquad s=255-r\n","$$\n"]},{"cell_type":"markdown","id":"8a80df0a-031e-499d-a707-0b645439a105","metadata":{},"outputs":[],"source":["We can perform intensity transformation on the toy image where $L = 3$:\n"]},{"cell_type":"code","id":"37e1327d-69d1-4bbf-af25-45cde917d86d","metadata":{},"outputs":[],"source":["neg_toy_image = -1 * toy_image + 255\n\nprint(\"toy image\\n\", neg_toy_image)\nprint(\"image negatives\\n\", neg_toy_image)"]},{"cell_type":"markdown","id":"3fa5f8ed-5cc3-499b-9538-4936a359e2a8","metadata":{},"outputs":[],"source":["We see darker intensity’s become brighter and brighter become darker, middle intensity’s remain the same.\n"]},{"cell_type":"code","id":"8e29bd9b-cd2c-484d-bed4-56f3047eead5","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.subplot(1, 2, 1) \nplt.imshow(toy_image,cmap=\"gray\")\nplt.subplot(1, 2, 2)\nplt.imshow(neg_toy_image,cmap=\"gray\")\nplt.show()\nprint(\"toy_image:\",toy_image)"]},{"cell_type":"markdown","id":"5effb065-ab59-42a7-aeb2-e67cdfc14882","metadata":{},"outputs":[],"source":["Reversing image intensity has many applications, including making it simpler to analyze medical images. Consider the mammogram with micro-calcifications on the upper quadrant:\n"]},{"cell_type":"code","id":"e89f93c2-09f0-45db-bbcc-86cf07259677","metadata":{},"outputs":[],"source":["image = cv2.imread(\"mammogram.png\", cv2.IMREAD_GRAYSCALE)\ncv2.rectangle(image, pt1=(160, 212), pt2=(250, 289), color = (255), thickness=2) \n\nplt.figure(figsize = (10,10))\nplt.imshow(image, cmap=\"gray\")\nplt.show()"]},{"cell_type":"markdown","id":"111a503f-2518-4b1c-8cb5-ed7c72b86673","metadata":{},"outputs":[],"source":["We can apply the intensity transformation:\n"]},{"cell_type":"code","id":"a1c62dd1-26d7-4ac3-b90f-4886715a5033","metadata":{},"outputs":[],"source":["img_neg = -1 * image + 255"]},{"cell_type":"markdown","id":"f681cff0-075c-4d6a-8e03-156f4da74f81","metadata":{},"outputs":[],"source":["We see the micro-calcifications in the image negatives is easier it is to analyze:\n"]},{"cell_type":"code","id":"8e3d8b1c-e9d3-4651-8ab5-0598b3062645","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(img_neg, cmap = \"gray\")\nplt.show()"]},{"cell_type":"markdown","id":"e8ed0aa5-271f-48f0-ab11-690a49da6e2e","metadata":{},"outputs":[],"source":["## Brightness and contrast adjustments\n"]},{"cell_type":"markdown","id":"1be38fef-f61f-4e7b-a677-565372a16c75","metadata":{},"outputs":[],"source":["We can use multiplication by $\\alpha$ for contrast control and addition by $\\beta$ to improve brightness control. This applies the Intensity Transformation as well. The image is $f(x,y)$ and the transformed image is $g(x,y)$, where $g(x,y) = \\alpha f(x,y) + \\beta$.\n"]},{"cell_type":"markdown","id":"89ee1f26-20d1-4afb-96af-9a73250e8e59","metadata":{},"outputs":[],"source":[" Rather than implementing via array operations, we use the function  <code>convertScaleAbs</code>. It scales, calculates absolute values, and converts the result to 8-bit so the values fall between $[0,255]$. For brightness control, we can set $\\alpha$ to 1 and $\\beta$ to 100: Remember the Good Hill image, it’s dark and hazy so let's see if we can improve it. \n"]},{"cell_type":"code","id":"42f38d5a-3fbd-4faf-bfb8-3570a4978f55","metadata":{},"outputs":[],"source":["alpha = 1 # Simple contrast control\nbeta = 100   # Simple brightness control   \nnew_image = cv2.convertScaleAbs(goldhill, alpha=alpha, beta=beta)"]},{"cell_type":"markdown","id":"e776e78e-c063-4849-ad27-c8e57c4d98d7","metadata":{},"outputs":[],"source":["We can plot the brighter image, it's much brighter :\n"]},{"cell_type":"code","id":"ee5581d9-723d-4a4a-9ce5-0909718c2810","metadata":{},"outputs":[],"source":["plot_image(goldhill, new_image, title_1 = \"Orignal\", title_2 = \"brightness control\")"]},{"cell_type":"markdown","id":"7c64bb93-9a28-41c6-9e0e-fd1c8cf2f4d0","metadata":{},"outputs":[],"source":["We see the brighter image's histogram is shifted:     \n"]},{"cell_type":"code","id":"b27310bd-9a62-4973-aa84-41d111ccdf29","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nplot_hist(goldhill, new_image, \"Orignal\", \"brightness control\")"]},{"cell_type":"markdown","id":"1f121dd4-75ce-4b3b-945c-23705d2e0471","metadata":{},"outputs":[],"source":["We can increase the contrast by increasing $\\alpha$:\n"]},{"cell_type":"code","id":"49f64ffe-c16d-4a61-9dc0-7b7cf615490d","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nalpha = 2# Simple contrast control\nbeta = 0 # Simple brightness control   # Simple brightness control\nnew_image = cv2.convertScaleAbs(goldhill, alpha=alpha, beta=beta)"]},{"cell_type":"markdown","id":"bcc39f50-52ea-413f-8f64-e1bda83934a7","metadata":{},"outputs":[],"source":["We can plot the image and its corresponding histogram:\n"]},{"cell_type":"code","id":"c501d4d7-ff75-4054-81d5-ae5eec3dee27","metadata":{},"outputs":[],"source":["plot_image(goldhill,new_image,\"Orignal\",\"contrast control\")"]},{"cell_type":"code","id":"6232c978-1401-4176-99db-ddeb05555d14","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nplot_hist(goldhill, new_image,\"Orignal\",\"contrast control\")"]},{"cell_type":"markdown","id":"47114a43-6a25-4f4f-8bce-1332360e2d66","metadata":{},"outputs":[],"source":["When plotting the image we see it's too bright. We can adapt the brightness by making the image darker and increasing the contrast at the same time. \n"]},{"cell_type":"code","id":"0e825ed5-9dba-4f36-a3ec-c0edbba2c344","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nalpha = 3 # Simple contrast control\nbeta = -200  # Simple brightness control   \nnew_image = cv2.convertScaleAbs(goldhill, alpha=alpha, beta=beta)"]},{"cell_type":"code","id":"416ae16f-af92-4984-983b-13f3a40f23dd","metadata":{},"outputs":[],"source":["plot_image(goldhill, new_image, \"Orignal\", \"brightness & contrast control\")"]},{"cell_type":"code","id":"7533da81-6c22-413f-ae60-7b803b9cf632","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nplot_hist(goldhill, new_image, \"Orignal\", \"brightness & contrast control\")"]},{"cell_type":"markdown","id":"505741d0-4beb-422e-9566-4d76df08a968","metadata":{},"outputs":[],"source":["There are other nonlinear methods to improve contrast and brightness, these methods have different sets of parameters. In general, it’s difficult to manually adjust the contrast and brightness parameter, but there are algorithms that improve contrast automatically.\n"]},{"cell_type":"markdown","id":"aa7bc2fd-96a1-40a7-b70c-e805b69b7e27","metadata":{},"outputs":[],"source":["## Histogram Equalization\n"]},{"cell_type":"markdown","id":"70dd8e1d-66f5-417d-b06c-3c5cc78b6060","metadata":{},"outputs":[],"source":["Histogram Equalization increases the contrast of images, by stretching out the range of the grayscale pixels; It does this by flatting  the histogram. We simply apply the function <code>cv2.equalizeHist</code>.\n"]},{"cell_type":"code","id":"905fd2de-da46-4c78-9a74-25e2544671fb","metadata":{},"outputs":[],"source":["zelda = cv2.imread(\"zelda.png\",cv2.IMREAD_GRAYSCALE)\nnew_image = cv2.equalizeHist(zelda)"]},{"cell_type":"markdown","id":"8d2fdde4-8d2d-457b-8d94-1366038ed1ba","metadata":{},"outputs":[],"source":["We can compare the image before and after Histogram Equalization, we see the contrast is improved. We see after the Histogram Equalization is applied, the histogram is stretched out:\n"]},{"cell_type":"code","id":"48c48922-f9a8-45f4-a19e-0c7dd78f7864","metadata":{},"outputs":[],"source":["plot_image(zelda,new_image,\"Orignal\",\"Histogram Equalization\")"]},{"cell_type":"code","id":"f8934714-96f4-4155-885d-c71b4de27fcf","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nplot_hist(zelda, new_image,\"Orignal\",\"Histogram Equalization\")"]},{"cell_type":"markdown","id":"f6f44be0-6c37-4c82-96e5-1aec95b68c69","metadata":{},"outputs":[],"source":["## Thresholding and Simple Segmentation \n"]},{"cell_type":"markdown","id":"fd2f26f2-5ea5-4b3d-8e97-81253661f3ce","metadata":{},"outputs":[],"source":["Thresholding is used in image segmentation this means extracting objects from an image. Image segmentation is used in many applications including extracting text, medical imaging, and industrial imaging.\n","Thresholding an image takes a threshold; If a particular pixel (i,j) is greater than that threshold it will set that pixel to some value usually 1 or 255, otherwise, it will set it to another value, usually zero. We can write a Python function that will perform thresholding and output a new image given some input grayscale image:\n"]},{"cell_type":"code","id":"380a6f86-feed-4545-9ac0-a2b5d9a094d9","metadata":{},"outputs":[],"source":["def thresholding(input_img,threshold,max_value=255, min_value=0):\n    N,M=input_img.shape\n    image_out=np.zeros((N,M),dtype=np.uint8)\n        \n    for i  in range(N):\n        for j in range(M):\n            if input_img[i,j]> threshold:\n                image_out[i,j]=max_value\n            else:\n                image_out[i,j]=min_value\n                \n    return image_out                             "]},{"cell_type":"markdown","id":"27477578-29ce-49d7-931a-40b15287b83d","metadata":{},"outputs":[],"source":["Consider the following toy image:\n"]},{"cell_type":"code","id":"de42524e-1a7f-4ef4-b35b-97be3df0ea54","metadata":{},"outputs":[],"source":["toy_image"]},{"cell_type":"markdown","id":"c9986026-4237-49dc-bad0-f548bdc8f19a","metadata":{},"outputs":[],"source":["We can apply thresholding, by setting all the values less than two to zero. \n"]},{"cell_type":"code","id":"099029a0-182e-43fc-b230-2c82a08556dc","metadata":{},"outputs":[],"source":["threshold = 1\nmax_value = 2\nmin_value = 0\nthresholding_toy = thresholding(toy_image, threshold=threshold, max_value=max_value, min_value=min_value)\nthresholding_toy"]},{"cell_type":"markdown","id":"147e3e7d-1010-4aee-a8dd-d36e113b0823","metadata":{},"outputs":[],"source":["We can compare the two images. In the new image we see all the gray values are now black:\n"]},{"cell_type":"code","id":"77538435-8e49-4f19-8fec-322136a6b28b","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10, 10))\nplt.subplot(1, 2, 1)\nplt.imshow(toy_image, cmap=\"gray\")\nplt.title(\"Original Image\")\nplt.subplot(1, 2, 2)\nplt.imshow(thresholding_toy, cmap=\"gray\")\nplt.title(\"Image After Thresholding\")\nplt.show()"]},{"cell_type":"markdown","id":"dda88af0-5847-4c9a-8c95-9b41527e69d3","metadata":{},"outputs":[],"source":["Consider the cameraman image:\n"]},{"cell_type":"code","id":"e9168735-8fa4-4a17-9403-999406918201","metadata":{},"outputs":[],"source":["image = cv2.imread(\"cameraman.jpeg\", cv2.IMREAD_GRAYSCALE)\nplt.figure(figsize=(10, 10))\nplt.imshow(image, cmap=\"gray\")\nplt.show()"]},{"cell_type":"markdown","id":"d6f544db-6fa9-4082-9dcb-7b124906da18","metadata":{},"outputs":[],"source":["We can see the histogram as two peeks, this means that there is a large proportion of pixels in those two ranges:\n"]},{"cell_type":"code","id":"8d7d7814-438c-4a63-a783-86250452183d","metadata":{},"outputs":[],"source":["hist = cv2.calcHist([goldhill], [0], None, [256], [0, 256])\nplt.bar(intensity_values, hist[:, 0], width=5)\nplt.title(\"Bar histogram\")\nplt.show()"]},{"cell_type":"markdown","id":"72ca763d-9507-4034-88ff-8dbfe195424a","metadata":{},"outputs":[],"source":["The cameraman corresponds to the darker pixels, therefore we can set the Threshold in such a way as to segment the cameraman. In this case, it looks to be slightly less than 90, let’s give it a try:\n"]},{"cell_type":"code","id":"6b063629-7556-4fc4-a8a2-a5a0012a4d78","metadata":{},"outputs":[],"source":["threshold = 87\nmax_value = 255\nmin_value = 0\nnew_image = thresholding(image, threshold=threshold, max_value=max_value, min_value=min_value)"]},{"cell_type":"markdown","id":"155365aa-23f3-4370-ad7f-9a1e992990d6","metadata":{},"outputs":[],"source":["We see the pixels corresponding to the cameraman are now zero and the rest are set to 255:\n"]},{"cell_type":"code","id":"4b216a94-ab7d-465f-bbac-bdd83e6c90e2","metadata":{},"outputs":[],"source":["plot_image(image, new_image, \"Orignal\", \"Image After Thresholding\")"]},{"cell_type":"code","id":"974acdf1-7cff-4099-8a1d-7964a195a14f","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,5))\nplot_hist(image, new_image, \"Orignal\", \"Image After Thresholding\")"]},{"cell_type":"markdown","id":"a702f66c-3147-4ffd-a701-b1569f8c0af0","metadata":{},"outputs":[],"source":["The function <code>cv.threshold</code> Applies a threshold to the gray image, with the following parameters:\n"]},{"cell_type":"markdown","id":"164057c3-8f81-4c8b-bec3-8a0a6c2e07ac","metadata":{},"outputs":[],"source":["<code>cv.threshold(grayscale image, threshold value, maximum value to use, thresholding type )</code>\n"]},{"cell_type":"markdown","id":"ccdf04d9-5fc6-4cbe-bc3c-c2969394c960","metadata":{},"outputs":[],"source":["The  parameter thresholding type is the type of thresholding we would like to perform. For example, we have basic thresholding: <code>cv2.THRESH_BINARY</code> this is the type we implemented in the function <code>thresholding</code>, it just a number:\n"]},{"cell_type":"code","id":"4143b66a-af9e-47f2-81e8-2e310e598c13","metadata":{},"outputs":[],"source":["cv2.THRESH_BINARY"]},{"cell_type":"markdown","id":"06e1c7a2-417e-4f06-b0b2-62f904cdcb5a","metadata":{},"outputs":[],"source":["We can apply thresholding to the image as follows:\n"]},{"cell_type":"code","id":"b796f7d0-ad8e-4fb5-a02d-aeb91e25029e","metadata":{},"outputs":[],"source":["ret, new_image = cv2.threshold(image,threshold,max_value,cv2.THRESH_BINARY)\nplot_image(image,new_image,\"Orignal\",\"Image After Thresholding\")\nplot_hist(image, new_image,\"Orignal\",\"Image After Thresholding\")"]},{"cell_type":"markdown","id":"ac5b795b-6b57-4546-9bc7-ab039ce3ee73","metadata":{},"outputs":[],"source":["<code>ret</code> is the threshold value and <code>new_image</code> is the image after thresholding has been applied. There are different threshold types, for example, cv2.THRESH_TRUNC will not change the values if the pixels are less than the threshold value:\n"]},{"cell_type":"code","id":"327683bb-d012-40b6-bff6-2f207ee62b85","metadata":{},"outputs":[],"source":["ret, new_image = cv2.threshold(image,86,255,cv2.THRESH_TRUNC)\nplot_image(image,new_image,\"Orignal\",\"Image After Thresholding\")\nplot_hist(image, new_image,\"Orignal\",\"Image After Thresholding\")"]},{"cell_type":"markdown","id":"a01deab5-48b4-41fa-bd06-e76883adbcc1","metadata":{},"outputs":[],"source":["We see that the darker elements have not changed and the lighter values are set to 255.\n"]},{"cell_type":"markdown","id":"7f2372b2-be8b-4644-8977-e6e688069a2a","metadata":{},"outputs":[],"source":[" Otsu's method <code>cv2.THRESH_OTSU</code> avoids having to choose a value and determines it automatically, using the histogram.\n"]},{"cell_type":"code","id":"f4d5ceed-78d8-4008-97c4-49e7b3c2d109","metadata":{},"outputs":[],"source":["ret, otsu = cv2.threshold(image,0,255,cv2.THRESH_OTSU)\nplot_image(image,otsu,\"Orignal\",\"Otsu\")\nplot_hist(image, otsu,\"Orignal\",\" Otsu's method\")"]},{"cell_type":"markdown","id":"370efe4f-8825-42b5-be03-cbbda2ce1332","metadata":{},"outputs":[],"source":["We assign the first row of pixels of the original array to the new array's last row. We repeat the process for every row, incrementing the row number for the original array and decreasing the new array's row index assigning the pixels accordingly.\n"]},{"cell_type":"code","id":"14a0d3b5-0ffa-4ace-9aa2-0a0e20a729e1","metadata":{},"outputs":[],"source":["ret"]},{"cell_type":"markdown","id":"5a30a368-1bf1-439d-bd78-9187cc8972e4","metadata":{},"outputs":[],"source":["<h2>Authors</h2>\n"]},{"cell_type":"markdown","id":"eebc219a-ffe0-41fb-a7cd-4aa199f8811f","metadata":{},"outputs":[],"source":[" [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","id":"3d6cfb81-840d-4ead-a407-2fadd5a60436","metadata":{},"outputs":[],"source":["# References \n"]},{"cell_type":"markdown","id":"2157775b-0add-491e-aec5-25d2adc62822","metadata":{},"outputs":[],"source":["[1]  Images were taken from: https://homepages.cae.wisc.edu/~ece533/images/\n","    \n","[2]  <a href='https://pillow.readthedocs.io/en/stable/index.html'>Pillow Docs</a>\n","\n","[3]  <a href='https://opencv.org/'>Open CV</a>\n","\n","[4] Gonzalez, Rafael C., and Richard E. Woods. \"Digital image processing.\" (2017).\n","\n","[5 ] Jian, Wushuai, Xueyan Sun, and Shuqian Luo. \"Computer-aided diagnosis of breast microcalcifications based on dual-tree complex wavelet transform.\" Biomedical engineering online 11.1 (2012): 1-12.\n"]},{"cell_type":"markdown","id":"ac7f675f-fa89-48c3-a917-b49bcaf543a4","metadata":{},"outputs":[],"source":["<!--<h2>Change Log</h2>-->\n"]},{"cell_type":"markdown","id":"c47e7e37-7993-4777-9ef0-d1f1c88cf19e","metadata":{},"outputs":[],"source":["<!--<table>\n","    <tr>\n","        <th>Date (YYYY-MM-DD)</th>\n","        <th>Version</th>\n","        <th>Changed By</th>\n","        <th>Change Description</th>\n","    </tr>\n","    <tr>\n","        <td>2020-07-20</td>\n","        <td>0.2</td>\n","        <td>Azim</td>\n","        <td>Modified Multiple Areas</td>\n","    </tr>\n","    <tr>\n","        <td>2020-07-17</td>\n","        <td>0.1</td>\n","        <td>Azim</td>\n","        <td>Created Lab Template</td>\n","    </tr>\n","</table>\n","-->\n"]},{"cell_type":"markdown","id":"2b714478-d651-44dd-a678-7c9288892b66","metadata":{},"outputs":[],"source":["\n","<h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"f11f8126f2dc787dbf57b38846bb600f6392a811d874d341c81104515ff895fd"},"nbformat":4,"nbformat_minor":4}